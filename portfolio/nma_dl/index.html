<!DOCTYPE html>
<html lang="en-us">
<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>Anjali Agarwal</title>
<meta name="description" content="Describe your website">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://anjaliagarwal8.github.io/css/bootstrap.min.css">
<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Roboto:400,300,700,400italic">
<link rel="stylesheet" href="https://anjaliagarwal8.github.io/css/font-awesome.min.css">
<link rel="stylesheet" href="https://anjaliagarwal8.github.io/css/owl.carousel.css">
<link rel="stylesheet" href="https://anjaliagarwal8.github.io/css/owl.theme.css">


  <link href="https://anjaliagarwal8.github.io/css/style.blue.css" rel="stylesheet" id="theme-stylesheet">

 

  
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
        <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  


<link href="https://anjaliagarwal8.github.io/css/custom.css" rel="stylesheet">
<link rel="shortcut icon" href="https://anjaliagarwal8.github.io/img/favicon.png">


</head>
<body>
  <div id="all">
      <div class="container-fluid">
          <div class="row row-offcanvas row-offcanvas-left">
              <div id="sidebar" class="col-xs-6 col-sm-4 col-md-3 sidebar-offcanvas">
  <div class="sidebar-content">
    <h1 class="sidebar-heading"><a href="https://anjaliagarwal8.github.io/">Anjali Agarwal</a></h1>
    
      <p class="sidebar-p">I am an Electrical Engineer, graduated from the Indian Institute of Technology Palakkad in 2020. I am currently      working as a Researcher at Tata Research Development and Design Centre.</p>
    
      <p class="sidebar-p">My research interest lies in Computational Neuroscience, Brain-Computer Interface, and Deep Learning.</p>
    
    <ul class="sidebar-menu">
      
        <li><a href="https://anjaliagarwal8.github.io/portfolio/">Home</a></li>
      
        <li><a href="https://anjaliagarwal8.github.io/about/">About</a></li>
      
        <li><a href="https://anjaliagarwal8.github.io/cv/Anjali_CV.pdf">CV</a></li>
      
    </ul>
    <p class="social">
  
  
  
  <a href="https://twitter.com/AnjaliAgrl" data-animate-hover="pulse" class="external twitter">
    <i class="fa fa-twitter"></i>
  </a>
  
  
  
  <a href="mailto:anjaliagarwal6174@gmail.com" data-animate-hover="pulse" class="email">
    <i class="fa fa-envelope"></i>
  </a>
  
  
  <a href="https://www.linkedin.com/in/anjaliagarwal8/" data-animate-hover="pulse" class="external">
    <i class="fa fa-linkedin"></i>
  </a>
  
  
  
  <a href="https://github.com/anjaliagarwal8" data-animate-hover="pulse" class="external">
    <i class="fa fa-github"></i>
  </a>
  
  
  
  <a href="https://www.youtube.com/channel/UCTwB7wHsPH7kwMkiX3scNIg" data-animate-hover="pulse" class="external">
    <i class="fa fa-youtube"></i>
  </a>
  
  
</p>


    <div class="copyright">
      <p class="credit">
        
          &copy;2022 Anjali Agarwal |
        
        Template by <a href="https://bootstrapious.com/free-templates" class="external">Bootstrapious.com</a>

&amp; ported to Hugo by <a href="https://github.com/kishaningithub">Kishan B</a>

      </p>
    </div>
  </div>
</div>

              
<div class="col-xs-12 col-sm-8 col-md-9 content-column white-background">
  <div class="small-navbar visible-xs">
  <button type="button" data-toggle="offcanvas" class="btn btn-ghost pull-left"> <i class="fa fa-align-left"> </i>Menu</button>
  <h1 class="small-navbar-heading"><a href="https://anjaliagarwal8.github.io/">Anjali Agarwal</a></h1>
</div>

  <div class="row">
    <div class="col-lg-8">
      <div class="content-column-content">
         <h1>VOneNet: a Hybrid CNN</h1>
         <p>Analysis of VOneNet towards adversarial attacks.</p>
<p>@ <a href="https://academy.neuromatch.io/">Neuromatch Academy</a></p>
<p>Checkout the code <a href="https://github.com/anjaliagarwal8/V1_Resnet-NMA">here</a></p>
<p>Neuromatch Academy has reignited my curiosity and appetite for knowledge. I had the most fun learning and building projects in neuroscience and deep learning during the two-month-long interactive course.<br>
During this time I got to collaborate with some awesome people and work on the analysis of CNN models that can prevent adversarial attacks on images.</p>
<h3 id="vonenet-a-hybrid-cnn-with-a-v1-neural-network-front-end">VOneNet: a Hybrid CNN with a V1 Neural Network Front-End</h3>
<p>With recent advances in Deep learning technology models can perform object detection tasks with high accuracy but are often fooled when adversarially attacked images are introduced. Images with some added noise or patch are called adversarially attacked images. These images can look the same to the human eye but can seem a completely different image to a highly accurate object detection model.</p>
<p><img src="/img/portfolio/nma_dl/adversarial_attack.PNG" alt="adversarial_attack"></p>
<p>Designing CNN models that are robust to adversarial images is a challenge. However, recent research has suggested that the models that adopt/mimic the primary visual processing of primates are more likely to improve the robustness. The similarity in the CNN and primate visual cortex is a well-explored area of research. Though there are differences in the higher visual areas(V2, V3, V4, and so on), the primary visual cortex (V1) has been shown to have strong similarities in terms of its computation and representation.</p>
<p><img src="/img/portfolio/nma_dl/v1_block.PNG" alt="v1_block"></p>
<p>Leveraging this, VOneNets are used to combat the processing of image perturbations. VOneNet contains VOneBlock, which is a hybrid neural network with a fixed weight front-end, shares the linear, nonlinear, and stochastic properties of the first layer, that is meant to reflect primate V1 as input to standard CNNs.</p>
<h3 id="data">Data</h3>
<p>We used the Imagenet dataset for testing the pretrained models.</p>
<p>For adding adversarial attacks to the images we used the Foolbox library, implementing the DeepFool L-infinity attack.</p>
<p><img src="/img/portfolio/nma_dl/clean_images.png" alt="clean_images">
<img src="/img/portfolio/nma_dl/perturbed_images.png" alt="perturbed_images"></p>
<h3 id="model-activations">Model Activations</h3>
<p>ResNet50 model was used as the backend convolutional neural network. Therefore, for comparison, we used the vanilla ResNet50 model and the hybrid ResNet50 model with V1 network at the front end (VOneResNet50).</p>
<p>After testing the models with clean and perturbed images, we collected the activations from each layer to inspect and visualize the difference in activations of each model to clean and perturbed images.</p>
<h3 id="representational-dissimilarity-analysis">Representational Dissimilarity Analysis</h3>
<p>For analysis of activations, we used the Representational Dissimilarity Analysis (RDA) method (analogous to RSA). We used Pearsonâ€™s Correlation coefficient to find the similarity between the activations of the model for clean and perturbed images and converted it into a dissimilarity coefficient. 
In the figure below you can see the dissimilarity or deviation coefficients for the V1 Resnet model and the vanilla Resnet model for one of the ImageNet images.</p>
<p><img src="/img/portfolio/nma_dl/single_deviation.png" alt="single_deviation"></p>
<p>We can observe that the V1 Resnet50 model has a low deviation between the clean and perturbed image as compared to the vanilla Resnet50 model.</p>
<p>We can also note that at four points the deviation of both the V1 Resnet50 model and vanilla Resnet50 model is zero, i.e. there is no difference in the clean and perturbed image. This occurs at 4, 12, 25, and 44 points on the x-axis.
This corresponds to layers:</p>
<p><strong>4  -  Layer 1, Bottleneck 0, Downsampling</strong></p>
<p><strong>12 - Layer 2, Bottleneck 0, Conv2</strong></p>
<p><strong>25 - Layer 3, Bottleneck 0, Conv2</strong></p>
<p><strong>44 - Layer 4, Bottleneck 0, Conv2</strong></p>
<p>In fact, Conv2 blocks in every bottleneck of every layer are where we observe the dips.
This observation can be generalized to all the images we tested the models on.</p>
<p><img src="/img/portfolio/nma_dl/all_deviation.png" alt="all_deviation"></p>
<h3 id="image-visualization">Image Visualization</h3>
<p>For visualizing each activation as an image, we used PCA to lower the dimension of each activation and then reshaped it as an image.</p>
<p><img src="/img/portfolio/nma_dl/resnet.png" alt="resnet">
<img src="/img/portfolio/nma_dl/v1.png" alt="v1"></p>
<p>Analyzing the images above, we can clearly see that although there is not much difference between V1 Resnet50 and Resnet50 model for clean images, for perturbed images there is a reasonable difference. This is because the V1 model is performing better on perturbed images than the Resnet50 model.</p>
<h3 id="conclusion">Conclusion</h3>
<p>Here we inspected and visualized the activations we obtain when we run clean and perturbed images through a normal ResNet50 model and a hybrid ResNet50 model with the front end as the V1 block inspired from the V1 part of the human visual system. 
We observed that the deviation between activations for clean and perturbed images in the case of VOneNet is much lower than for the normal ResNet model which gives proof that the VOneNet model is robust and is not affected by adversarial attacks. Some more insights we built analyzing the deviation maps are the dips at specific layers where the deviation is zero for both the models, the occurrence of which is not clear and provides an opportunity for future work.</p>
<p><strong>Team:  Ishwarya Chandramouli, Anjali Agarwal, Ranjith Jaganathan</strong></p>
<h4 id="references">References</h4>
<ol>
<li>Dapello, J., Marques, T., Schrimpf, M., Geiger, F., Cox, D.D., &amp; DiCarlo, J.J. (2020). Simulating a Primary Visual Cortex at the Front of CNNs Improves Robustness to Image Perturbations. bioRxiv.</li>
<li>Kriegeskorte, N., Mur, M., &amp; Bandettini, P. (2008). Representational similarity analysis - connecting the branches of systems neuroscience. Frontiers in systems neuroscience, 2, 4. <a href="https://doi.org/10.3389/neuro.06.004.2008">https://doi.org/10.3389/neuro.06.004.2008</a></li>
</ol>
         
      </div>
    </div>
  </div>
</div>

          </div>
      </div>
  </div>
  <script src="https://anjaliagarwal8.github.io/js/jquery.min.js"></script>
<script src="https://anjaliagarwal8.github.io/js/bootstrap.min.js"></script>
<script src="https://anjaliagarwal8.github.io/js/jquery.cookie.js"> </script>
<script src="https://anjaliagarwal8.github.io/js/ekko-lightbox.js"></script>
<script src="https://anjaliagarwal8.github.io/js/jquery.scrollTo.min.js"></script>
<script src="https://anjaliagarwal8.github.io/js/masonry.pkgd.min.js"></script>
<script src="https://anjaliagarwal8.github.io/js/imagesloaded.pkgd.min.js"></script>
<script src="https://anjaliagarwal8.github.io/js/owl.carousel.min.js"></script>
<script src="https://anjaliagarwal8.github.io/js/front.js"></script>



</body>
</html>
